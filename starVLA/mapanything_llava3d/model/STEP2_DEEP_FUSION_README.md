# æ­¥éª¤ 2: LLaVA3D Deep Fusion å®ç°å®Œæˆ âœ…

**å®Œæˆæ—¥æœŸ**: 2024-12-30  
**æ ¸å¿ƒæ–‡ä»¶**: `modeling_llava3d_v2_dev.py`  
**å®ç°è¡Œæ•°**: ç¬¬ 169-509 è¡Œ

---

## ğŸ“‹ å®ç°æ¦‚è¿°

æ­¥éª¤ 2 æˆåŠŸå®ç°äº† `LLaVA3DWithActionExpertModel` çš„**åŒæµè”åˆæ³¨æ„åŠ›ï¼ˆDeep Fusionï¼‰**æœºåˆ¶ï¼Œè¿™æ˜¯æ•´ä¸ª Deep Fusion Flow Matching æ¶æ„çš„æ ¸å¿ƒåŸºç¡€ã€‚

### æ ¸å¿ƒç‰¹æ€§

âœ… **ä¸‰ç§å‰å‘æ¨¡å¼**
- **Prefix-only**: çº¯ LLaVA3D å‰å‘ï¼Œç”¨äºè¯­è¨€ç”Ÿæˆå’Œæ„å»º KV cache
- **Suffix-only**: Expert æµç‹¬ç«‹å‰å‘ï¼Œç”¨äºåŠ¨ä½œå»å™ªæ­¥éª¤
- **Prefix+Suffix**: åŒæµè”åˆæ³¨æ„åŠ›ï¼Œç”¨äº Flow Matching è®­ç»ƒ

âœ… **é€å±‚è”åˆæ³¨æ„åŠ›**
- å®ç°äº† `_compute_layer_complete` æ–¹æ³•
- prefix å’Œ suffix åœ¨æ¯ä¸€å±‚éƒ½é€šè¿‡è”åˆæ³¨æ„åŠ›äº’ç›¸æ„ŸçŸ¥
- å®Œå…¨å¤åˆ» PI0/PaliGemma çš„ Deep Fusion è®¾è®¡

âœ… **æ¨¡å‹ç±»å‹æ— å…³**
- è‡ªåŠ¨æ£€æµ‹å¹¶æ”¯æŒ LLaMA å’Œ Mistral æ¶æ„
- ç»Ÿä¸€çš„ RoPE åº”ç”¨å’Œæ³¨æ„åŠ›è®¡ç®—æ¥å£

âœ… **å‚æ•°é«˜æ•ˆ**
- Expert æµå¤ç”¨ LLaVA3D çš„å±‚æƒé‡ï¼ˆå‚æ•°å…±äº«ï¼‰
- ä»…é¢å¤–å¢åŠ  expert final norm å±‚

---

## ğŸ—ï¸ æ¶æ„è®¾è®¡

### ç±»ç»“æ„

```python
class LLaVA3DWithActionExpertModel(nn.Module):
    """
    LLaVA3D Deep Fusion æ¨¡å‹
    
    æ¶æ„ï¼š
    - Base Model: LLaVA3D (LlamaModel / MistralModel)
    - Expert Stream: å…±äº« base å±‚æƒé‡ + ç‹¬ç«‹ final norm
    - Fusion: æ¯å±‚è”åˆæ³¨æ„åŠ›
    """
    
    def __init__(self, base_llava, expert_config=None)
    def forward(self, attention_mask, position_ids, inputs_embeds=[prefix, suffix], ...)
    def _compute_layer_complete(self, layer_idx, prefix_hidden, suffix_hidden, ...)
    def _apply_rotary_pos_emb(self, query, key, position_ids)
    def _compute_attention(self, layer, Q, K, V, mask)
    def _create_norm_layer(self)
```

### è”åˆæ³¨æ„åŠ›æµç¨‹

```
è¾“å…¥: prefix_embs [B, L_p, H], suffix_embs [B, L_s, H]
  â”‚
  â””â”€> å¯¹æ¯ä¸€å±‚ layer_idx:
       â”‚
       â”œâ”€ LayerNorm (prefix & suffix)
       â”œâ”€ QKV æŠ•å½± (prefix & suffix)
       â”œâ”€ æ‹¼æ¥ QKV: [prefix; suffix] â†’ [B, H, L_p+L_s, D]
       â”œâ”€ åº”ç”¨ RoPE
       â”œâ”€ è”åˆæ³¨æ„åŠ›è®¡ç®— â­ (prefix â†” suffix äº’ç›¸æ„ŸçŸ¥)
       â”œâ”€ æ‹†åˆ†: [prefix_out; suffix_out]
       â”œâ”€ O-projection + ç¬¬ä¸€æ®‹å·®
       â”œâ”€ MLP + ç¬¬äºŒæ®‹å·®
       â””â”€> è¾“å‡º prefix_hidden, suffix_hidden (è¿›å…¥ä¸‹ä¸€å±‚)
```

#### ä½ç½®ç¼–ç å¤„ç†ï¼ˆæ›´æ–°è¯´æ˜ï¼‰

- åœ¨ Deep Fusion è®­ç»ƒæ¨¡å¼ä¸‹ï¼Œprefix å’Œ suffix è¢«è§†ä¸ºä¸€ä¸ªæ–°çš„ joint åºåˆ—
- joint åºåˆ—çš„ `position_ids` é‡‡ç”¨ç»Ÿä¸€ä» 0 å¼€å§‹çš„è¿ç»­ç¼–å·ï¼š
  - prefix éƒ¨åˆ†: `0 .. L_p-1`
  - suffix éƒ¨åˆ†: `L_p .. L_p+L_s-1`
- ä¸å†å¤ç”¨å¤–éƒ¨ä¼ å…¥çš„ç»å¯¹ `position_ids`ï¼Œä»¥é¿å…ï¼š
  - RoPE çš„ cos/sin æŒ‰ã€Œæœ€å¤§ç»å¯¹ä½ç½®ã€ç”Ÿæˆ
  - è€Œ `joint_q` çš„å®é™…åºåˆ—é•¿åº¦æ˜¯ `L_p+L_s`
- è¿™æ ·å¯ä»¥ç¡®ä¿åœ¨ `_apply_rotary_pos_emb` ä¸­ï¼š
  - `joint_q` / `joint_k` çš„ seq_len ä¸ `position_ids` å®Œå…¨ä¸€è‡´
  - ä¸ä¼šå‡ºç°ã€ŒThe size of tensor a (seq) must match tensor b (pos)ã€è¿™ç±»ç»´åº¦ä¸åŒ¹é…é”™è¯¯

---

## ğŸ”§ ä½¿ç”¨æ–¹æ³•

### åˆå§‹åŒ–

```python
from modeling_llava3d_v2_dev import LLaVA3DForCausalLMV2, LLaVA3DWithActionExpertModel

# åŠ è½½ base LLaVA3D æ¨¡å‹
base_llava = LLaVA3DForCausalLMV2.from_pretrained("path/to/llava3d")

# åˆ›å»º Deep Fusion æ¨¡å‹
model_with_expert = LLaVA3DWithActionExpertModel(
    base_llava=base_llava,
    expert_config=None  # å¯é€‰ï¼šexpert é…ç½®
)
```

### å‰å‘ä¼ æ’­

#### Mode 1: Prefix-onlyï¼ˆè¯­è¨€ç”Ÿæˆï¼‰

```python
# è¾“å…¥ï¼šå›¾åƒ + æ–‡æœ¬ embeddings
prefix_embs = get_image_text_embeddings(...)  # [B, L_p, H]

# å‰å‘
outputs, past_kv = model_with_expert(
    inputs_embeds=[prefix_embs, None],
    use_cache=True,  # ç”Ÿæˆ KV cache
)

prefix_output = outputs[0]  # [B, L_p, H]
# å¯ä»¥æ¥ lm_head ç”Ÿæˆæ–‡æœ¬
```

#### Mode 2: Suffix-onlyï¼ˆåŠ¨ä½œå»å™ªï¼‰

```python
# è¾“å…¥ï¼šçŠ¶æ€ + åŠ¨ä½œ + æ—¶é—´ embeddings
suffix_embs = get_state_action_time_embeddings(...)  # [B, L_s, H]

# å‰å‘
outputs, _ = model_with_expert(
    inputs_embeds=[None, suffix_embs],
)

suffix_output = outputs[1]  # [B, L_s, H]
# å¯ä»¥æ¥ action_head é¢„æµ‹åŠ¨ä½œ
```

#### Mode 3: Prefix+Suffixï¼ˆDeep Fusion è®­ç»ƒï¼‰

```python
# è¾“å…¥ï¼šä¸¤è·¯éƒ½æœ‰
prefix_embs = get_image_text_embeddings(...)  # [B, L_p, H]
suffix_embs = get_state_action_time_embeddings(...)  # [B, L_s, H]

# å‰å‘ï¼ˆDeep Fusionï¼‰
outputs, _ = model_with_expert(
    inputs_embeds=[prefix_embs, suffix_embs],
    attention_mask=joint_mask,  # [B, L_p + L_s]
)

prefix_output, suffix_output = outputs
# prefix å’Œ suffix åœ¨æ¯å±‚éƒ½äº’ç›¸æ„ŸçŸ¥äº†ï¼
```

---

## ğŸ§ª æµ‹è¯•éªŒè¯

è¿è¡Œæµ‹è¯•è„šæœ¬ï¼š

```bash
cd /cpfs01/qianfy_workspace/zzq_vla/SpatialVLA_llava3d/model
python test_deep_fusion_step2.py
```

**æ³¨æ„**: æµ‹è¯•éœ€è¦çœŸå®çš„ LLaVA3D æ¨¡å‹ã€‚å»ºè®®ä½¿ç”¨å°å‹æ¨¡å‹ï¼ˆå¦‚ llava-v1.5-7bï¼‰ã€‚

### æµ‹è¯•å†…å®¹

- âœ… æ¨¡å‹åˆå§‹åŒ–å’Œç±»å‹æ£€æµ‹
- âœ… Prefix-only æ¨¡å¼å½¢çŠ¶éªŒè¯
- âœ… Suffix-only æ¨¡å¼å½¢çŠ¶éªŒè¯
- âœ… Prefix+Suffix Deep Fusion å½¢çŠ¶éªŒè¯
- âœ… æ¢¯åº¦æµåŠ¨æµ‹è¯•

å½“å‰æµ‹è¯•è„šæœ¬é»˜è®¤ä» `/2025233147/zzq/SpatialVLA_llava3d/checkpoints/llava3d_deepfusion_base` åŠ è½½ä¸€ä¸ªå°å‹ LLaVA3D æ¨¡å‹ï¼Œå¦‚éœ€æ›´æ¢æ¨¡å‹å¯ä¿®æ”¹ `test_deep_fusion_step2.py` é¡¶éƒ¨çš„è·¯å¾„å¸¸é‡ã€‚

---

## ğŸ“Š æ€§èƒ½ç‰¹æ€§

### å·²å®ç°

| ç‰¹æ€§ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| åŒæµè”åˆæ³¨æ„åŠ› | âœ… | æ ¸å¿ƒ Deep Fusion é€»è¾‘ |
| åŒå®½å¤š expert | âœ… | Base ä¸ Expert åŒå®½ã€å‚æ•°ç‹¬ç«‹ |
| æ¨¡å‹ç±»å‹é€‚é… | âœ… | æ”¯æŒ LLaMA + Mistral |
| ä¸‰ç§å‰å‘æ¨¡å¼ | âœ… | prefix/suffix/joint |
| æ¢¯åº¦æµåŠ¨ | âœ… | æ”¯æŒåå‘ä¼ æ’­è®­ç»ƒ |

---

## ğŸ§  Base / Expert å¯¹é½çº¦æŸä¸ openpi å¯¹æ¯”ï¼ˆè®¾è®¡è¯´æ˜ï¼‰

è¿™ä¸€èŠ‚è®°å½• Deep Fusion é‡Œ base model ä¸ action expert åœ¨ã€Œè”åˆæ³¨æ„åŠ›å±‚ã€ä¸Šçš„æ¥å£çº¦æŸï¼Œä»¥åŠä¸ openpiï¼ˆPaliGemma + Gemma expertï¼‰çš„å¼‚åŒï¼Œæ–¹ä¾¿åç»­åšå° expertã€adapter ç­‰æ”¹åŠ¨æ—¶ä¸è¸©å‘ã€‚

### 1. è”åˆæ³¨æ„åŠ›å±‚çš„ç¡¬æ€§çº¦æŸï¼ˆfusion ç©ºé—´ï¼‰

åœ¨ `_compute_layer_complete` ä¸­ï¼Œprefix å’Œ suffix çš„ hidden åœ¨æ¯ä¸€å±‚ä¼šè¢«æ‹¼æˆä¸€ä¸ª joint åºåˆ—ï¼Œç»Ÿä¸€åšä¸€æ¬¡å¤šå¤´æ³¨æ„åŠ›ã€‚å°±æ³¨æ„åŠ›è®¡ç®—æœ¬èº«æ¥è¯´ï¼Œæœ‰ä¸€ç»„ã€Œå¿…é¡»åœ¨ joint attention è¿™ä¸€åˆ»å¯¹é½ã€çš„æ¡ä»¶ï¼š

- Q/K/V çš„ head ç©ºé—´
  - `num_attention_heads` å¿…é¡»ä¸€è‡´ï¼ˆå½“å‰ä¸º 32ï¼‰
  - `head_dim` å¿…é¡»ä¸€è‡´ï¼ˆå½“å‰ä¸º 128ï¼‰
  - `num_key_value_heads` ä»¥åŠ GQA å±•å¼€æ–¹å¼å¿…é¡»ä¸€è‡´ï¼ˆå½“å‰å±•å¼€åç­‰ä»·äº 32ï¼‰
- RoPE é…ç½®ï¼ˆåœ¨ joint attention æ‰€åœ¨ç©ºé—´ï¼‰
  - å‚ä¸ joint attention çš„ Q/K éƒ½ä½¿ç”¨ç›¸åŒçš„ RoPE è§„åˆ™
  - å½“å‰å®ç°ä¸­ï¼Œç›´æ¥å¤ç”¨ LLaVA3D text backbone çš„ RoPEï¼ˆtheta=10000 ç­‰ï¼‰

ä»¥ä¸Šçº¦æŸå¯ä»¥ç†è§£ä¸ºï¼š**æ— è®º prefix/suffix åˆ†åˆ«æ¥è‡ªå“ªæ¡åˆ†æ”¯ï¼Œåªè¦è¦è¢«æ‹¼åˆ°åŒä¸€æ¬¡æ³¨æ„åŠ›é‡Œï¼Œå®ƒä»¬çš„ Q/K å°±å¿…é¡»è½åœ¨åŒä¸€ä¸ªå‡ ä½•ä¸€è‡´çš„ head ç©ºé—´é‡Œ**ã€‚å¦åˆ™ï¼š

- å½¢çŠ¶ä¸Šï¼šQã€K çš„ç»´åº¦æ— æ³•åšåˆæ³•çš„çŸ©é˜µä¹˜ï¼ˆç›´æ¥æŠ¥é”™ï¼‰
- å‡ ä½•ä¸Šï¼šRoPE ä¸ä¸€è‡´ä¼šå¯¼è‡´ã€ŒåŒæ ·çš„ç›¸å¯¹ä½ç½®ã€åœ¨ä¸åŒåˆ†æ”¯ä¸Šè¢«ç¼–ç æˆå®Œå…¨ä¸åŒçš„æ—‹è½¬æ¨¡å¼ï¼Œsoftmax å¾ˆéš¾å­¦åˆ°ç¨³å®šçš„è·¨ prefix/suffix æ³¨æ„æ¨¡å¼

å½“å‰ dev ç‰ˆæœ¬ä¸ºäº†ç®€åŒ–ï¼š

- expert åˆ†æ”¯ä½¿ç”¨ä¸ base ç›¸åŒçš„ LLaMA block é…ç½®ï¼ˆåŒå®½ï¼ŒåŒæ ·çš„ head ç»´åº¦ä¸ RoPE è§„åˆ™ï¼‰ï¼Œä½†æ‹¥æœ‰ç‹¬ç«‹çš„ä¸€å¥—å±‚å‚æ•°ï¼›
- åœ¨æ¯ä¸€å±‚ joint attention çš„æ—¶å€™ï¼Œprefix/suffix çš„ Q/K/V éƒ½æ¥è‡ªåŒä¸€ä¸ªå‡ ä½•ä¸€è‡´çš„ head ç©ºé—´ï¼ˆç”± fusion é…ç½®æ§åˆ¶ï¼‰ã€‚

### 2. å“ªäº›å¯ä»¥ä¸å¯¹é½ï¼Œäº¤ç»™ adapter è§£å†³

ä»æ¶æ„ä¸Šçœ‹ï¼Œ**çœŸæ­£ç¡¬æ€§è¦æ±‚ç»Ÿä¸€çš„åªæ˜¯ã€Œå‚ä¸ joint attention çš„é‚£ä¸€å±‚ç©ºé—´ã€**ï¼Œè€Œä¸æ˜¯æ•´ä¸ª expert ç½‘ç»œçš„å†…éƒ¨ç»“æ„ã€‚è¿™æ„å‘³ç€ï¼š

- å¯ä»¥ä¸åŒçš„éƒ¨åˆ†ï¼ˆå¦‚æœå¼•å…¥ adapterï¼‰
  - expert å†…éƒ¨çš„ `hidden_size`ï¼ˆä¾‹å¦‚ 1024/2048/â€¦ï¼‰
  - expert è‡ªå·±çš„ head æ•°ã€depthã€MLP å®½åº¦ç­‰
- éœ€è¦åœ¨ joint attention å‰ç»Ÿä¸€åˆ°çš„ fusion ç©ºé—´
  - ä¸€èˆ¬å›ºå®šä¸ºä¸ base ä¸€è‡´çš„ `hidden_dim_fusion = 4096`
  - ç»Ÿä¸€çš„ `num_heads_fusion = 32`ã€`head_dim_fusion = 128`

ä¸€ç§è‡ªç„¶çš„åç»­æ‰©å±•è·¯å¾„æ˜¯ï¼š

- expert å†…éƒ¨ä½œä¸ºã€Œä»»æ„ llamaâ€‘like å°æ¨¡å‹ã€ï¼Œä¾‹å¦‚ hidden=2048ã€heads=16 ç­‰
- åœ¨è¿›å…¥ `_compute_layer_complete` å‰ï¼š
  - å¯¹ suffix hidden å…ˆåš `Linear(D_expert -> 4096)` ä½œä¸º adapter
  - å†ç”¨ç»Ÿä¸€çš„ q_proj/k_proj/v_projï¼ˆ4096â†’4096ï¼Œæ‹†æˆ 32Ã—128ï¼‰è¿›å…¥ joint attention
- è¿™æ ·å¯ä»¥åœ¨ä¸æ”¹å˜ joint attention å‡ ä½•è§„èŒƒçš„å‰æä¸‹ï¼Œè®© expert çœŸæ­£å˜å°

å½“å‰ dev å®ç°å¤„äºã€Œexpert ä¸ base åœ¨ head ç©ºé—´é…ç½®ä¸Šå®Œå…¨å¯¹é½ã€ä½†å‚æ•°ç‹¬ç«‹ã€çš„é˜¶æ®µï¼Œæœªæ¥å¦‚æœè¦åšå° expertï¼Œå¯ä»¥å›´ç»•ä¸Šè¿° fusion ç©ºé—´è§„èŒƒï¼Œåœ¨ä¸ä½¿ç”¨æ˜¾å¼ adapter çš„å‰æä¸‹ï¼Œé€šè¿‡ per-expert qkv/o_proj å®ç°å®½åº¦å¯¹é½ã€‚

### 3. openpi ä¸­ PaliGemma + Gemma expert çš„å®ç°æ–¹å¼

openpi çš„ flow æ¨¡å‹å¯¹åº”å…³ç³»å¤§è‡´æ˜¯ï¼š

- baseï¼šPaliGemmaï¼ˆè§†è§‰ + è¯­è¨€ï¼Œå¤§æ¨¡å‹ï¼‰
- expertï¼šå°å‹ Gemmaï¼ˆä¾‹å¦‚ 300Mï¼‰ä½œä¸º action expert
- æ·±åº¦äº¤äº’åº•åº§ï¼š
  - JAX ç«¯ï¼š`openpi/models/gemma.py::Module` å’Œ `Attention`
  - PyTorch ç«¯ï¼š`openpi/models_pytorch/gemma_pytorch.py::PaliGemmaWithExpertModel`

å®ƒä»¬çš„ä¸€ä¸ªå…³é”®ç‰¹ç‚¹æ˜¯ï¼š**åœ¨æ³¨æ„åŠ›å±‚ä¸Šï¼Œbase å’Œ expert è¢«å®ç°ä¸ºåŒä¸€ä¸ªå¤š expert Transformer é‡Œçš„ä¸¤ä¸ª expertï¼Œè€Œä¸æ˜¯ä¸¤æ¡å®Œå…¨ç‹¬ç«‹çš„ backbone åœ¨é¡¶å±‚å† crossâ€‘attention ä¸€ä¸‹**ã€‚

å…·ä½“æ¥è¯´ï¼ˆJAX ç‰ˆæœ¬ä¸ºä¾‹ï¼‰ï¼š

- `Module.configs = [paligemma_config, action_expert_config]`
- `Attention.__call__` ä¼šï¼š
  - å¯¹æ¯ä¸ª expert çš„è¾“å…¥åˆ†åˆ«åš q/k/v æŠ•å½±ï¼ˆæƒé‡ä¸åŒï¼‰
  - åœ¨ seq ç»´åº¦æŠŠæ‰€æœ‰ expert çš„ q/k/v æ‹¼æ¥æˆä¸€ä¸ªé•¿åºåˆ—
  - åœ¨æ‹¼æ¥åçš„ q/k ä¸Šç»Ÿä¸€åº”ç”¨ RoPEã€ç»Ÿä¸€åšä¸€æ¬¡ attention
  - å†æŒ‰ token æ®µåˆ‡å›æ¯ä¸ª expertï¼Œåˆ†åˆ«ç»è¿‡å„è‡ªçš„ o_proj å’Œ MLP
- æ³¨æ„åŠ›å±‚å‰é¢æœ‰ assertï¼š

  ```python
  assert all(config.head_dim      == self.configs[0].head_dim      for config in self.configs)
  assert all(config.num_heads     == self.configs[0].num_heads     for config in self.configs)
  assert all(config.num_kv_heads  == self.configs[0].num_kv_heads  for config in self.configs)
  ```

è¿™è¯´æ˜åœ¨ openpi é‡Œï¼š

- **base expertï¼ˆPaliGemmaï¼‰å’Œ action expertï¼ˆGemma å°æ¨¡å‹ï¼‰åœ¨ attention head ç»´åº¦ä¸Šæ˜¯å¼ºåˆ¶å®Œå…¨ä¸€è‡´çš„**
- å®ƒä»¬åœ¨æ¯ä¸€å±‚ attention ä¸­è¢«å½“åšåŒä¸€ä¸ª joint åºåˆ—å¤„ç†
- åŒºåˆ«åªåœ¨äºï¼š
  - æ¯ä¸ª expert æœ‰è‡ªå·±çš„ qkv/o_proj/MLP å‚æ•°
  - ä½†å…±äº«åŒä¸€ä¸ª RoPE å‡ ä½•å’Œ head ç©ºé—´

PyTorch ç‰ˆæœ¬ (`PaliGemmaWithExpertModel`) ä¹Ÿé‡‡å–äº†ç±»ä¼¼ç­–ç•¥ï¼šåœ¨æ¯ä¸€å±‚ä¸­æ‰‹åŠ¨ä» `paligemma.language_model` å’Œ `gemma_expert.model` æ‹¿å‡ºå¯¹åº”å±‚ï¼Œè®¡ç®—å„è‡ªçš„ q/k/vï¼Œç„¶ååœ¨ä¸€ä¸ª attention kernel é‡Œ jointï¼Œå†åˆ‡å›ä¸¤è·¯ã€‚

### 4. æœ¬é¡¹ç›®ä¸ openpi çš„å¯¹åº”å…³ç³»ä¸å·®å¼‚

- å…±åŒç‚¹
  - éƒ½æ˜¯ã€Œprefixï¼ˆè§†è§‰+è¯­è¨€ï¼‰ + suffixï¼ˆstate+action+timeï¼‰ã€åœ¨æ¯ä¸€å±‚åšè”åˆæ³¨æ„åŠ›
  - éƒ½è¦æ±‚å‚ä¸ joint attention çš„ head ç©ºé—´åœ¨å‡ ä½•ä¸Šç»Ÿä¸€ï¼ˆhead_dim/heads/kv_headsã€RoPEï¼‰
- å·®å¼‚ç‚¹
  - openpiï¼š
    - ä»ä¸€å¼€å§‹å°±æŠŠ PaliGemma + Gemma expert å†™æˆä¸€ä¸ªå¤š expert çš„å•ä¸€ Transformer
    - attention å±‚å¤©ç„¶æ˜¯ä¸€ä¸ª joint attentionï¼Œä¸éœ€è¦æ˜¾å¼â€œæ¥ä¸¤ä¸ªç‹¬ç«‹ backboneâ€
  - æœ¬é¡¹ç›®ï¼š
    - èµ·ç‚¹æ˜¯ä¸€ä¸ªå·²ç»å­˜åœ¨çš„ LLaVA3D æ–‡æœ¬ backbone
    - åœ¨æ­¤åŸºç¡€ä¸Šé€šè¿‡ `LLaVA3DWithActionExpertModel` åŠ äº†ä¸€æ¡ expert æµï¼Œå¹¶åœ¨ `_compute_layer_complete` ä¸­å®ç° joint attention
    - å½“å‰ dev ç‰ˆæœ¬è®© expert å®Œå…¨å¤ç”¨ base çš„å±‚ç»“æ„ä¸é…ç½®ï¼Œä»¥ç®€åŒ–å®ç°

åç»­å¦‚æœè¦å‘ openpi é æ‹¢ï¼ˆä½¿ç”¨æ›´å°ä½†ç»“æ„å…¼å®¹çš„ expertï¼‰ï¼š

- ä¸€ç§æ–¹æ¡ˆæ˜¯ï¼šä¿æŒ joint attention æ‰€åœ¨çš„ fusion ç©ºé—´ä¸ base å®Œå…¨ä¸€è‡´ï¼Œä»…åœ¨ expert å†…éƒ¨é€šè¿‡æ›´æµ…çš„å±‚æ•°æˆ–æ›´çª„çš„ MLP å®ç°ã€Œç˜¦èº«ã€
- å¦ä¸€ç§æ–¹æ¡ˆæ˜¯ï¼šå…è®¸ expert å†…éƒ¨ä½¿ç”¨æ›´å°çš„ hidden/headï¼Œè¿›å…¥ joint attention å‰å¼ºåˆ¶é€šè¿‡ adapter æ˜ å°„åˆ°ç»Ÿä¸€çš„ 4096 ç»´èåˆç©ºé—´ï¼Œå†ä½¿ç”¨ç»Ÿä¸€çš„ qkv+RoPE åš attention

æ— è®ºé€‰æ‹©å“ªæ¡è·¯çº¿ï¼Œä¸Šè¿°å¯¹é½çº¦æŸéƒ½æ˜¯åç»­æ”¹åŠ¨éœ€è¦éµå®ˆçš„æ¥å£å¥‘çº¦ã€‚

---

## ğŸ§© é¢„å®šæ–¹æ¡ˆæ¦‚è§ˆï¼šæ—  adapter å° expert + multi-expert attention

ç»“åˆè®¨è®ºï¼Œç›®å‰æˆ‘ä»¬åœ¨æœ¬é¡¹ç›®ä¸­é€‰æ‹©çš„åç»­è·¯çº¿ä¸ºï¼š

- ç»Ÿä¸€é‡‡ç”¨ LLaMA å®¶æ—æ¶æ„ï¼ˆä¸ç°æœ‰ LLaVA3D ä¸€è‡´ï¼‰ï¼›
- åœ¨ LLaMA block é…æ–¹ä¸‹è®¾è®¡ä¸€ä¸ªæ›´çª„ã€æ›´æµ…çš„åŠ¨ä½œ expertï¼›
- ä¸ä½¿ç”¨æ˜¾å¼ adapterï¼Œè€Œæ˜¯é‡å†™/æ‰©å±• `_compute_layer_complete` ä¸ºå¤šä¸“å®¶æ³¨æ„åŠ›ï¼ˆmulti-expert attentionï¼‰ï¼š
  - æ‰€æœ‰ expert åœ¨ head ç»´åº¦ä¸ RoPE ä¸Šå®Œå…¨ä¸€è‡´ï¼›
  - å„è‡ªé€šè¿‡è‡ªå·±çš„ qkv/o_proj å°†ä¸åŒå®½åº¦çš„ hidden æ¥å…¥åŒä¸€ä¸ªæ³¨æ„åŠ›å¤´ç©ºé—´ï¼›
  - åœ¨è¿™ä¸ªç»Ÿä¸€ç©ºé—´é‡Œè¿›è¡Œ Q/K/V æ‹¼æ¥ä¸ joint attentionã€‚

è¯¥æ–¹æ¡ˆçš„è¯¦ç»†è®¾è®¡ä¸å¼€å‘æ­¥éª¤è§ï¼š[llava3d_deep_fusion_plan.md](file:///2025233147/zzq/SpatialVLA_llava3d/model/llava3d_deep_fusion_plan.md) ä¸­çš„ã€Œäº”ã€å° expert + multi-expert attention æ–¹æ¡ˆï¼ˆæ—  adapter è·¯çº¿ï¼‰ã€ç« èŠ‚ã€‚

### å¾…ä¼˜åŒ–

| ç‰¹æ€§ | çŠ¶æ€ | ä¼˜å…ˆçº§ |
|------|------|--------|
| Suffix-only KV cache | âš ï¸ | é«˜ |
| Gradient Checkpointing | âš ï¸ | ä¸­ |
| Flash Attention 2 | âš ï¸ | ä¸­ |
| å•å…ƒæµ‹è¯•è¦†ç›– | âš ï¸ | é«˜ |

---

## ğŸ” ä»£ç è¯¦è§£

### å…³é”®æ–¹æ³•ï¼š`_compute_layer_complete`

è¿™æ˜¯ Deep Fusion çš„æ ¸å¿ƒå®ç°ï¼Œå®Œæ•´ä»£ç è§ `modeling_llava3d_v2_dev.py` ç¬¬ 275-334 è¡Œã€‚

```python
def _compute_layer_complete(
    self,
    layer_idx: int,
    prefix_hidden: torch.Tensor,
    suffix_hidden: torch.Tensor,
    attention_mask: Optional[torch.Tensor],
    position_ids: Optional[torch.LongTensor],
):
    """
    é€å±‚è”åˆæ³¨æ„åŠ›è®¡ç®—
    
    æ ¸å¿ƒæ€æƒ³ï¼š
    1. åˆ†åˆ«å¯¹ prefix å’Œ suffix åš LayerNorm å’Œ QKV æŠ•å½±
    2. åœ¨åºåˆ—ç»´åº¦æ‹¼æ¥ Q, K, V
    3. ç»Ÿä¸€åº”ç”¨ RoPE å’Œè®¡ç®—æ³¨æ„åŠ›ï¼ˆprefix â†” suffix äº’ç›¸å¯è§ï¼‰
    4. æ‹†åˆ†è¾“å‡ºï¼Œå„è‡ªåš O-projã€æ®‹å·®ã€MLP
    5. è¿”å›æ›´æ–°åçš„ hidden states
    """
    layer = self.base_model.layers[layer_idx]
    
    # Step 1: LayerNorm
    prefix_normed = layer.input_layernorm(prefix_hidden)
    suffix_normed = layer.input_layernorm(suffix_hidden)
    
    # Step 2: QKV projection
    prefix_q/k/v = layer.self_attn.q/k/v_proj(prefix_normed)
    suffix_q/k/v = layer.self_attn.q/k/v_proj(suffix_normed)
    
    # Step 3: Concatenate (â­ Deep Fusion çš„å…³é”®)
    joint_q = torch.cat([prefix_q, suffix_q], dim=2)
    joint_k = torch.cat([prefix_k, suffix_k], dim=2)
    joint_v = torch.cat([prefix_v, suffix_v], dim=2)
    
    # Step 4: RoPE
    joint_q, joint_k = self._apply_rotary_pos_emb(...)
    
    # Step 5: Joint Attention
    joint_attn_output = self._compute_attention(...)
    
    # Step 6: Split back
    prefix_attn_output = joint_attn_output[:, :prefix_len, :]
    suffix_attn_output = joint_attn_output[:, prefix_len:, :]
    
    # Step 7-8: O-proj, Residual, MLP
    prefix_hidden = prefix_hidden + layer.self_attn.o_proj(prefix_attn_output)
    prefix_hidden = prefix_hidden + layer.mlp(layer.post_attention_layernorm(prefix_hidden))
    # åŒç†å¤„ç† suffix
    
    return prefix_hidden, suffix_hidden
```

---

## ğŸ“ˆ ä¸ PI0 å®ç°å¯¹æ¯”

| ç»´åº¦ | PI0 (PaliGemma) | LLaVA3D (æœ¬å®ç°) |
|------|-----------------|-------------------|
| **æ¶æ„** | PaliGemma + Gemma Expert | LLaVA3D ç»Ÿä¸€åº•åº§ |
| **å‚æ•°é‡** | ä¸¤ä¸ªç‹¬ç«‹æ¨¡å‹ | å‚æ•°å…±äº«ï¼ˆæ›´é«˜æ•ˆï¼‰ |
| **è”åˆæ³¨æ„åŠ›** | âœ… é€å±‚ QKV æ‹¼æ¥ | âœ… é€å±‚ QKV æ‹¼æ¥ |
| **æ¨¡å‹æ”¯æŒ** | ä»… Gemma | LLaMA + Mistral |
| **ä»£ç å¤æ‚åº¦** | é«˜ï¼ˆä¸¤å¥—å±‚ï¼‰ | ä¸­ï¼ˆå…±äº«å±‚ï¼‰ |
| **çµæ´»æ€§** | ä½ | é«˜ï¼ˆå¯æ‰©å±•åˆ°å…¶ä»– LLMï¼‰ |

---

## ğŸš€ ä¸‹ä¸€æ­¥ï¼ˆæ­¥éª¤ 3ï¼‰

æ­¥éª¤ 2 å·²ç»å®Œæˆäº† Deep Fusion çš„åº•å±‚åŸºç¡€è®¾æ–½ï¼Œæ¥ä¸‹æ¥éœ€è¦ï¼š

### æ­¥éª¤ 3: æ”¹é€  `FlowMatchingActionExpert`

**ç›®æ ‡**: å°† Flow Matching çš„ç½‘ç»œå‰å‘ä» Gemma åˆ‡æ¢åˆ° `LLaVA3DWithActionExpertModel`

**ä»»åŠ¡æ¸…å•**:
- [ ] åˆ é™¤å¯¹ Gemma çš„ä¾èµ–ï¼ˆ`GemmaPreTrainedModel`, `GemmaModel`ï¼‰
- [ ] ä¿ç•™ Flow Matching æ•°å­¦é€»è¾‘ï¼ˆ`t`, `noise`, `x_t`, `u_t`, Euler è¿­ä»£ï¼‰
- [ ] é‡æ–°è®¾è®¡æ¥å£ï¼šæ¥æ”¶ `prefix_embs` å’Œ `suffix_embs`
- [ ] è°ƒç”¨ `LLaVA3DWithActionExpertModel` è¿›è¡Œå‰å‘
- [ ] åœ¨ `compute_loss` ä¸­ä½¿ç”¨ Deep Fusionï¼ˆMode 3ï¼‰
- [ ] åœ¨ `sample_actions` ä¸­ä½¿ç”¨ prefix cache + suffix å»å™ªï¼ˆMode 1 + Mode 2 å¾ªç¯ï¼‰

### æ­¥éª¤ 4: é›†æˆåˆ° `MapAnythingLlava3DForConditionalGeneration`

**ç›®æ ‡**: åœ¨é¡¶å±‚ wrapper ä¸­æ„é€  prefix/suffix embeddings å¹¶è°ƒç”¨æ–°ä¸“å®¶

**ä»»åŠ¡æ¸…å•**:
- [ ] å®ç° `get_prefix_embeddings`: image + geometric + text â†’ prefix_embs
- [ ] å®ç° `get_suffix_embeddings`: state + noisy_actions + time â†’ suffix_embs
- [ ] åœ¨ `forward` ä¸­è°ƒç”¨ Deep Fusion è®­ç»ƒè·¯å¾„
- [ ] åœ¨ `predict_action` ä¸­å®ç° prefix cache + å¾ªç¯å»å™ª

---

## ğŸ“š å‚è€ƒæ–‡æ¡£

- **å®ç°æ–¹æ¡ˆ**: `llava3d_deep_fusion_plan.md`ï¼ˆå·²æ›´æ–°æ­¥éª¤ 2 çŠ¶æ€ï¼‰
- **PI0 å‚è€ƒå®ç°**: `mapAnythingLlava3dPi0.5/openpi/models_pytorch/gemma_pytorch.py`
- **DiT/Flow Matching å‚è€ƒå®ç°**: `starVLA/starVLA/model/modules/action_model`ï¼ˆç”¨äºç†è§£å¦‚ä½•æ¨¡å—åŒ–æ‹†åˆ†åŠ¨ä½œç¼–ç ã€DiT ä¸»å¹²å’Œ Flow Matching å¤´ï¼‰
- **æµ‹è¯•è„šæœ¬**: `test_deep_fusion_step2.py`

---

## âœ¨ è´¡çŒ®è€…

**å®ç°è€…**: AI Assistant  
**å®¡æ ¸è€…**: å¾…å®š  
**æ—¥æœŸ**: 2024-12-30

---

## ğŸ“ æ›´æ–°æ—¥å¿—

### 2024-12-30
- âœ… å®Œæˆ `LLaVA3DWithActionExpertModel` æ ¸å¿ƒå®ç°
- âœ… å®ç° `_compute_layer_complete` é€å±‚è”åˆæ³¨æ„åŠ›
- âœ… æ”¯æŒä¸‰ç§å‰å‘æ¨¡å¼ï¼ˆprefix/suffix/jointï¼‰
- âœ… æ·»åŠ æ¨¡å‹ç±»å‹è‡ªåŠ¨æ£€æµ‹ï¼ˆLLaMA/Mistralï¼‰
- âœ… å®ç°å‚æ•°å…±äº«ç­–ç•¥
- âœ… æ›´æ–°æ–‡æ¡£å’Œæµ‹è¯•è„šæœ¬

---

**çŠ¶æ€**: âœ… æ­¥éª¤ 2 å®Œæˆ  
**ä¸‹ä¸€æ­¥**: ğŸš§ æ­¥éª¤ 3 - æ”¹é€  FlowMatchingActionExpert
