run_id: mapanything_llava3dact_vla
run_root_dir: results/Checkpoints
seed: 42
trackers: [jsonl, swanlab]
wandb_entity: "bbbforbazinga"
wandb_project: mapanything_llava3d_starvla
is_debug: false

framework:
  name: MapAnythingLlava3DPI
  mapanything_llava3d:
    base_vlm: ./checkpoints/mapanything_llava3d_vlm_base
    attn_implementation: flash_attention_2
    vl_hidden_dim: 4096
    prefix_image_dropout_prob: 0.1
    prefix_lang_dropout_prob: 0.1
    use_geometric_branch: true
  dino:
    dino_backbone: dinov2_vits14

  action_model:
    action_model_type: DiT-B
    hidden_size: 1024     # 和 DiT 最后的 projection 对应，用于 ActionDecoder
    add_pos_embed: True
    max_seq_len: 1024
    action_dim: 7
    state_dim: 7
    future_action_window_size: 7
    action_horizon: 8
    past_action_window_size: 0
    repeated_diffusion_steps: 2
    noise_beta_alpha: 1.5
    noise_beta_beta: 1.0
    noise_s: 0.999
    num_timestep_buckets: 1000
    num_inference_timesteps: 4
    num_target_vision_tokens: 32
    vl_layer_selection: last
    diffusion_model_cfg:    # DiT Transformers 的参数
      cross_attention_dim: 4096 # VLM 的 dim
      dropout: 0.1
      final_dropout: true
      interleave_self_attention: true
      norm_type: "ada_norm"
      num_layers: 16
      output_dim: 1024
      positional_embeddings: null


datasets:
  vla_data:
    dataset_py: lerobot_datasets
    data_root_dir: /2025233147/zzq/SpatialVLA_llava3d/playground/Datasets/LEROBOT_LIBERO_DATA
    data_mix: bridge_rt_1 # bridge_rt_1
    action_type: delta_ee
    CoT_prompt: "Your task is {instruction}. To identify the key objects for your task. Locate their bounding boxes in [x1,y1,x2,y2] format."
    CoT_answer: bbox
    default_image_resolution: [3, 224, 224]
    per_device_batch_size: 16
    num_workers: 16
    video_backend: torchvision_av


trainer:
  epochs: 100
  max_train_steps: 100000
  num_warmup_steps: 5000
  lang_freeze_steps: 0
  save_interval: 5000
  # save_interval: 5
  eval_interval: 100
  learning_rate:
    base: 2.5e-05
    # language model: use a smaller lr,主要让几何/视觉更用力适配
    # mapanythingllava3d_vlm_interface.model.language_model: 5.0e-06
    # # geom 分支：提高 lr
    # mapanythingllava3d_vlm_interface.model.geometric_model: 5.0e-05
    # mapanythingllava3d_vlm_interface.model.geometric_projector: 5.0e-05
    # mapanythingllava3d_vlm_interface.model.fusion_projector: 5.0e-05
    # # vision 分支：提高 lr
    # mapanythingllava3d_vlm_interface.model.vision_tower: 5.0e-05
    # mapanythingllava3d_vlm_interface.model.vision_projector: 5.0e-05
    # action 头保持不变
    action_model: 1.0e-04
  lr_scheduler_type: cosine_with_min_lr
  scheduler_specific_kwargs:
    min_lr: 1.0e-06
  # freeze_modules: 'mapanythingllava3d_vlm_interface.model.vision_tower, mapanythingllava3d_vlm_interface.model.geometric_model'
  freeze_modules: ''
  early_stopping:
    enabled: true
    metric: action_dit_loss
    mode: min
    patience: 100000     # 例如：连续 5000 step 没有下降就停
    min_delta: 0.0
  loss_scale:
    vla: 1.0
  max_grad_norm: 1.0
  warmup_ratio: 0.1
  weight_decay: 0.0
  logging_frequency: 10
  gradient_clipping: 1.0
  gradient_accumulation_steps: 1
  geom_vision_only_steps: 0
  optimizer:
    name: AdamW
    betas: [0.9, 0.95]
    eps: 1.0e-08
    weight_decay: 1.0e-08

  # parameters to be determined
  is_resume: false
  resume_epoch: null
  resume_step: null
  enable_gradient_checkpointing: true
  enable_mixed_precision_training: true
