"""
metrics.py

Utility classes defining a Metrics container and multiple Trackers to enable model/stage-specific logging to various
endpoints (e.g., JSONL local logs, Weights & Biases).
"""




from typing import Tuple
import re
import json
import numpy as np
import torch

from accelerate.logging import get_logger
logger = get_logger(__name__)

# TODO è¿™é‡Œæˆ–è®¸å†™åˆ°trainer å†…éƒ¨æ›´å¥½ï¼Ÿ
# TODO ä¹‹ç±»çš„æ–‡ä»¶æ˜¯å¦éœ€è¦é‡æ„ï¼Ÿ

# === Define Tracker Interface ===
# 

# utils/cli_parser.py

def normalize_dotlist_args(args): # å…¶å®å¯ä»¥äº¤ç»™ OmegaConf å†…éƒ¨çš„ï¼Œ ä½†æ˜¯è€ƒè™‘åˆ°è¦ç»™ç”¨æˆ·æš´éœ²è¿™ä¸ªå‚æ•°çš„æ„å»ºè¿‡ç¨‹
    """
    Convert ['--x.y', 'val'] and ['--flag'] â†’ ['x.y=val', 'flag=true']
    """
    normalized = []
    skip = False
    for i in range(len(args)):
        if skip:
            skip = False
            continue

        arg = args[i]
        if arg.startswith("--"):
            key = arg.lstrip("-")
            if "=" in key:
                normalized.append(key)
            elif i + 1 < len(args) and not args[i + 1].startswith("--"):
                normalized.append(f"{key}={args[i + 1]}")
                skip = True
            else:
                normalized.append(f"{key}=true")
        else:
            pass  # skip orphaned values
    return normalized


def build_param_lr_groups(model, cfg): # TODO åé¢è¦å’Œ trainer ç»‘å®š
    """
    æ ¹æ® cfg.trainer.learning_rate æ„å»ºå¤š param group çš„å‚æ•°ç»„ã€‚
    æ”¯æŒæŒ‡å®šæ¨¡å—ä½¿ç”¨ä¸åŒå­¦ä¹ ç‡ï¼Œå…¶ä½™ä½¿ç”¨ baseã€‚
    
    Args:
        vla: nn.Module æ¨¡å‹å¯¹è±¡
        cfg: é…ç½®å¯¹è±¡ï¼Œè¦æ±‚æœ‰ cfg.trainer.learning_rate å­—å…¸

    Returns:
        List[Dict]: å¯ç”¨äº torch.optim æ„å»º optimizer çš„ param_groups
    """

    lr_cfg = cfg.trainer.learning_rate
    base_lr = lr_cfg.get("base", 1e-4)  # é»˜è®¤ base å­¦ä¹ ç‡

    used_params = set()
    param_groups = []

    for module_name, lr in lr_cfg.items():
        if module_name == "base":
            continue
        # å°è¯•æŒ‰ module_name åœ¨ vla ä¸‹æ‰¾åˆ°æ¨¡å—ï¼ˆæ”¯æŒåµŒå¥—è·¯å¾„ï¼‰
        module = model
        try:
            for attr in module_name.split("."):
                module = getattr(module, attr)
            params = list(module.parameters())
            param_groups.append({"params": params, "lr": lr, "name": module_name})
            used_params.update(id(p) for p in params)
        except AttributeError:
            ReferenceError(f"âš ï¸ æ¨¡å—è·¯å¾„ `{module_name}` æ— æ³•åœ¨ vla ä¸­æ‰¾åˆ°")

    # å°†å…¶ä½™æœªä½¿ç”¨çš„å‚æ•°åˆ†é… base å­¦ä¹ ç‡
    other_params = [p for p in model.parameters() if id(p) not in used_params]
    if other_params:
        param_groups.append({"params": other_params, "lr": base_lr, "name": "base"})

    return param_groups


import torch.distributed as dist

def only_main_process(func):
    """
    è£…é¥°å™¨ï¼šä»…åœ¨ä¸»è¿›ç¨‹ï¼ˆrank=0ï¼‰æ—¶è¿è¡Œ
    """
    def wrapper(*args, **kwargs):
        if dist.is_initialized() and dist.get_rank() != 0:
            return None  # éä¸»è¿›ç¨‹ä¸æ‰§è¡Œ
        return func(*args, **kwargs)
    return wrapper


from torchvision.ops import box_iou
from PIL import Image
def resize_images(images, target_size=(224, 224)):
    """
    é€’å½’è°ƒæ•´åµŒå¥—åˆ—è¡¨ä¸­çš„æ‰€æœ‰å›¾åƒå¤§å°ã€‚
    
    :param images: åµŒå¥—çš„å›¾åƒåˆ—è¡¨æˆ–å•ä¸ªå›¾åƒã€‚
    :param target_size: è°ƒæ•´åçš„ç›®æ ‡å¤§å° (width, height)ã€‚
    :return: è°ƒæ•´å¤§å°åçš„å›¾åƒåˆ—è¡¨ï¼Œä¿æŒåŸå§‹åµŒå¥—ç»“æ„ã€‚
    """
    if isinstance(images, Image.Image):  # å¦‚æœæ˜¯å•ä¸ª PIL å›¾åƒ
        return images.resize(target_size)
    elif isinstance(images, list):  # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œé€’å½’å¤„ç†æ¯ä¸ªå…ƒç´ 
        return [resize_images(img, target_size) for img in images]
    else:
        raise ValueError("Unsupported image type or structure.")

import torch.distributed as dist

class TrainerUtils:
    @staticmethod
    def freeze_backbones(model, freeze_modules=""):
        """
        æ ¹æ®ç›¸å¯¹æ¨¡å—è·¯å¾„åˆ—è¡¨ï¼ˆpatternsï¼‰ç›´æ¥å†»ç»“æŒ‡å®šå­æ¨¡å—ï¼Œä¸å†é€’å½’æŸ¥æ‰¾æ‰€æœ‰å­æ¨¡å—åç§°ï¼š
          - patterns: ä» config.trainer.freeze_modules ä¸­è¯»å–ï¼Œç”¨é€—å·åˆ†éš”å¾—åˆ°çš„â€œç›¸å¯¹è·¯å¾„â€åˆ—è¡¨
            ä¾‹å¦‚ "qwen_vl_interface, action_model.net"ï¼Œ
            å°±æ„å‘³ç€å†»ç»“ model.qwen_vl_interface å’Œ model.action_model.netã€‚
        è¿”å›å€¼ï¼š
          - model: 
        """
        frozen = []
        if freeze_modules:
            # æ‹†åˆ†å¹¶å»é™¤ç©ºç™½
            patterns = [p.strip() for p in freeze_modules.split(",") if p.strip()] if freeze_modules else []

            for path in patterns:
                # å°†â€œç›¸å¯¹è·¯å¾„â€æŒ‰ç‚¹æ‹†åˆ†ï¼Œä¾‹å¦‚ "action_model.net" â†’ ["action_model", "net"]
                attrs = path.split(".")
                module = model
                try:
                    for attr in attrs:
                        module = getattr(module, attr)
                    # å¦‚æœæˆåŠŸ get åˆ° moduleï¼Œå°±æŠŠå®ƒå’Œå®ƒçš„æ‰€æœ‰å­æ¨¡å—å‚æ•°éƒ½ freeze
                    for param in module.parameters():
                        param.requires_grad = False
                    frozen.append(path)
                except AttributeError:
                    # å¦‚æœæŸä¸€çº§å±æ€§ä¸å­˜åœ¨ï¼Œå°±è·³è¿‡å¹¶æ‰“å°è­¦å‘Š
                    print(f"âš ï¸ æ¨¡å—è·¯å¾„ä¸å­˜åœ¨ï¼Œæ— æ³•å†»ç»“ï¼š{path}")
                    continue

        dist.barrier()  # åˆ†å¸ƒå¼è®­ç»ƒæ—¶åŒæ­¥
        print(f"ğŸ”’ Frozen modules (by relative path): {frozen}")
        return model
    
    @staticmethod 
    def print_trainable_parameters(model):
        """
        æ‰“å°æ¨¡å‹çš„æ€»å‚æ•°æ•°é‡å’Œå¯è®­ç»ƒå‚æ•°æ•°é‡
        :param model: PyTorch æ¨¡å‹å®ä¾‹
        """
        if dist.get_rank() != 0:
            return
        print("ğŸ“Š æ¨¡å‹å‚æ•°ç»Ÿè®¡ï¼š")
        num_params = sum(p.numel() for p in model.parameters())
        num_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f"# Parameters (in millions): {num_params / 10**6:.3f} Total, {num_trainable_params / 10**6:.3f} Trainable")
        return num_params, num_trainable_params
    
    @staticmethod
    def load_pretrained_backbones(model, checkpoint_path=None, reload_modules=None):
        """
        åŠ è½½ checkpointï¼š
        - å¦‚æœè®¾ç½®äº† reload_modules æŒ‰è·¯å¾„éƒ¨åˆ†åŠ è½½
        - å¦åˆ™ â†’ åŠ è½½æ•´ä¸ªæ¨¡å‹å‚æ•°ï¼ˆè¦†ç›– modelï¼‰

        è¿”å›ï¼š
            æ›¿æ¢ï¼Œloaded_modules: æˆåŠŸåŠ è½½å‚æ•°çš„æ¨¡å—è·¯å¾„åˆ—è¡¨ï¼›è‹¥å…¨å±€åŠ è½½åˆ™ä¸º ["<full_model>"]
        """
        if not checkpoint_path:
            return []  
        if dist.get_rank() == 0:
            print(f"ğŸ“¦ æ­£åœ¨åŠ è½½ checkpoint: {checkpoint_path}")
        try:
            checkpoint = torch.load(checkpoint_path, map_location="cpu")
        except Exception as e:
            raise RuntimeError(f"âŒ åŠ è½½ checkpoint å¤±è´¥: {e}")

        loaded_modules = []

        if reload_modules:  # éƒ¨åˆ†åŠ è½½
            module_paths = [p.strip() for p in reload_modules.split(",") if p.strip()]
            for path in module_paths:
                reload_modules = path.split(".")
                module = model
                try:
                    for module_name in reload_modules:  # é€çº§æ‰¾åˆ°è¦ä¿®æ”¹çš„æ¨¡å—
                        module = getattr(module, module_name)
                    prefix = path + "."
                    sub_state_dict = {
                        k[len(prefix):]: v
                        for k, v in checkpoint.items()
                        if k.startswith(prefix)
                    }
                    if sub_state_dict:
                        module.load_state_dict(sub_state_dict, strict=True)
                        if dist.get_rank() == 0:
                            print(f"âœ… å‚æ•°å·²åŠ è½½åˆ°æ¨¡å— '{path}'")
                        loaded_modules.append(path)
                    else:
                        print(f"âš ï¸ checkpoint ä¸­æœªæ‰¾åˆ° '{path}' ç›¸å…³å‚æ•°")
                except AttributeError:
                    print(f"âŒ æ— æ³•æ‰¾åˆ°æ¨¡å—è·¯å¾„ï¼š{path}")
        else:  # å…¨éƒ¨åŠ è½½
            try:
                model.load_state_dict(checkpoint, strict=True)
                if dist.get_rank() == 0:
                    print("âœ… å·²åŠ è½½<full_model>æ¨¡å‹å‚æ•°")
                loaded_modules = ["<full_model>"]
            except Exception as e:
                raise RuntimeError(f"âŒ åŠ è½½å®Œæ•´æ¨¡å‹å¤±è´¥: {e}")
        return model
    
    @staticmethod
    def print_freeze_status(model):
        """
        æ‰“å°æ¨¡å‹ä¸­æ¯ä¸ªå‚æ•°çš„å†»ç»“çŠ¶æ€
        :param model: PyTorch æ¨¡å‹å®ä¾‹
        """
        for name, param in model.named_parameters():
            status = "Frozen" if not param.requires_grad else "Trainable"
            print(f"{name:60s}  |  {status}")

    @staticmethod
    def setup_distributed_training(accelerator, *components):
        """
        ä½¿ç”¨ Accelerator å‡†å¤‡åˆ†å¸ƒå¼è®­ç»ƒç»„ä»¶
        :param accelerator: Accelerate çš„å®ä¾‹
        :param components: ä»»æ„æ•°é‡çš„ç»„ä»¶ï¼ˆå¦‚æ¨¡å‹ã€ä¼˜åŒ–å™¨ã€æ•°æ®åŠ è½½å™¨ç­‰ï¼‰
        :return: å‡†å¤‡å¥½çš„åˆ†å¸ƒå¼ç»„ä»¶ï¼ˆä¸è¾“å…¥é¡ºåºä¸€è‡´ï¼‰
        """
        # ä½¿ç”¨ accelerator.prepare æ–¹æ³•åŒ…è£…ç»„ä»¶
        prepared_components = accelerator.prepare(*components)
        return prepared_components
    @staticmethod
    def euclidean_distance(predicted: np.ndarray, ground_truth: np.ndarray) -> float:
        return np.linalg.norm(predicted - ground_truth)

    @staticmethod
    def _reset_dataloader(dataloader, epoch_counter):
        """å®‰å…¨é‡ç½®dataloaderè¿­ä»£å™¨"""
        # 1. æ›´æ–°epochè®¡æ•°
        epoch_counter += 1
        
        # 2. è®¾ç½®æ–°epochï¼ˆåˆ†å¸ƒå¼æ ¸å¿ƒï¼‰
        if hasattr(dataloader, "sampler") and callable(getattr(dataloader.sampler, "set_epoch", None)):
            dataloader.sampler.set_epoch(epoch_counter)
        
        # 3. åˆ›å»ºæ–°è¿­ä»£å™¨
        return iter(dataloader), epoch_counter
    
    @staticmethod
    def compute_grad_angle_with_stats(grads_a: list[torch.Tensor], grads_v: list[torch.Tensor]) -> Tuple[float, float]:
        """
        è®¡ç®—ä¸¤ç»„æ¢¯åº¦å‘é‡çš„ä½™å¼¦å¤¹è§’ï¼ˆåº¦ï¼‰ï¼Œå¹¶ç»Ÿè®¡å¹³å‡å¤¹è§’å’Œæ–¹å·®ã€‚
        grads_a, grads_v: ä¸åŒä¸€å‚æ•°åˆ—è¡¨ interface_params å¯¹åº”çš„æ¢¯åº¦ Tensor åˆ—è¡¨
        è¿”å›:
            mean_angle_deg: å¹³å‡å¤¹è§’ï¼ˆåº¦ï¼‰
            angle_variance: å¤¹è§’æ–¹å·®
        """
        angle_degs = []
        
        # TODO æ€ä¹ˆçœ‹è¿™ä¸ªå¤¹è§’æ‰åˆç†ï¼Ÿ
        # åˆ†å—è®¡ç®—æ¯ä¸ªæ¢¯åº¦çš„å¤¹è§’ grads_a[0].shape = 1280, 3, 14, 14
        # æ¢¯åº¦å¤ªå¤šä¸å¥½çœ‹ï¼Ÿ
        # grads_1 = grads_a[0][0]  # å½¢çŠ¶ä¸º [3, 14, 14]
        # grads_2 = grads_v[0][0]
        # grads_a = grads_1.view(-1, 3)  # é‡å¡‘ä¸º [196, 3]
        # grads_v = grads_2.view(-1, 3)

        # lang linear
        # reshape ä¸º 14*14, 3
        # layer
        grads_action = grads_a[0]  # å½¢çŠ¶ä¸º [2048, 11008]
        grads_action = grads_action[:32, :7] # åªå–å‰7ä¸ªå…ƒç´ , é¿å…é«˜ç»´ç©ºé—´cosim å¤±æ•ˆ
        grads_vl = grads_v[0]  # å½¢çŠ¶ä¸º [2048, 11008]
        grads_vl = grads_vl[:32, :7] # åªå–å‰32ä¸ªå…ƒç´ , 7 ç»´åº¦, é¿å…é«˜ç»´ç©ºé—´cosim å¤±æ•ˆ
        # PCA åœ¨çœ‹ï¼ŸFVD full rank
        for g_a, g_v in zip(grads_action, grads_vl):
            dot = torch.sum(g_a * g_v)
            norm_a_sq = torch.sum(g_a * g_a)
            norm_v_sq = torch.sum(g_v * g_v)

            # é¿å…é™¤é›¶
            norm_a = torch.sqrt(norm_a_sq + 1e-16)
            norm_v = torch.sqrt(norm_v_sq + 1e-16)

            cos_sim = (dot / (norm_a * norm_v)).clamp(-1.0, 1.0)
            angle_rad = torch.acos(cos_sim)
            angle_deg = angle_rad * (180.0 / torch.pi)

            angle_degs.append(angle_deg.item())

        # è®¡ç®—å¹³å‡å¤¹è§’å’Œæ–¹å·®
        angle_degs_tensor = torch.tensor(angle_degs)
        mean_angle_deg = torch.mean(angle_degs_tensor).item()
        angle_variance = torch.sqrt(torch.var(angle_degs_tensor)).item()
        # dist.barrier() # @DEBUG
        return mean_angle_deg, angle_variance

    @staticmethod
    def pcgrad_project(grads_a: list[torch.Tensor],
                    grads_v: list[torch.Tensor]
                    ) -> list[torch.Tensor]:
        """
        å¯¹ç¬¬äºŒç»„æ¢¯åº¦ grads_v åº”ç”¨ PCGrad æŠ•å½±ï¼ŒæŠ‘åˆ¶ä¸ grads_a é—´çš„è´Ÿè¿ç§»
        å¦‚æœä¸¤ç»„æ¢¯åº¦çš„ç‚¹ç§¯ < 0ï¼Œåˆ™ï¼š
            grads_v <- grads_v - (dot / ||grads_a||^2) * grads_a
        è¿”å›æ–°çš„ grads_v åˆ—è¡¨
        """
        # å…ˆç®— dot å’Œ ||grads_a||^2
        dot, norm_a_sq = 0.0, 0.0
        for g_a, g_v in zip(grads_a, grads_v):
            dot       += torch.sum(g_a * g_v)
            norm_a_sq += torch.sum(g_a * g_a)

        if dot < 0:
            coeff = dot / (norm_a_sq + 1e-6)
            # æŠ•å½±
            grads_v = [g_v - coeff * g_a for g_a, g_v in zip(grads_a, grads_v)]

        return grads_v

    @staticmethod
    def eval_qwenpi(qwenpi, dataloader, num_batches=20):  # TODO è¿™ä¸ªæ–¹æ³•è§£è€¦æ€§ä¸å¤Ÿå¥½
        """
        è¯„ä¼° QwenQFormerDiT æ¨¡å‹ï¼Œè®¡ç®— IoU å’ŒåŠ¨ä½œè·ç¦»ã€‚
        
        Args:
            qwenpi: QwenQFormerDiT æ¨¡å‹å®ä¾‹ã€‚
            dataloader: æ•°æ®åŠ è½½å™¨ã€‚
            num_batches: è¯„ä¼°çš„æ‰¹æ¬¡æ•°é‡ã€‚
        
        Returns:
            dict: åŒ…å« IoU å’ŒåŠ¨ä½œè·ç¦»çš„è¯„ä»·ç»“æœã€‚
        """
        iou_scores = []
        action_distances = []
        count = 0

        dataset_iter = iter(dataloader)
        while count < num_batches:
            try:
                batch_samples = next(dataset_iter)
                count += 1
            except StopIteration:
                break

            # æå–æ•°æ®
            images = [example["image"] for example in batch_samples]
            instructions = [example["lang"] for example in batch_samples]
            actions = [example["action"] for example in batch_samples]
            solutions = [example["solution"] for example in batch_samples]

            # æ¨¡å‹é¢„æµ‹
            predicted_solutions, normalized_actions = qwenpi.predict_action_withCoT(
                images=images,
                instructions=instructions,
                use_ddim=False,
                num_ddim_steps=20
            )

            # æå–å¹¶è½¬æ¢é¢„æµ‹ç»“æœ
            parsed_solutions = []
            for solution in predicted_solutions:
                parsed_solution = TrainerUtils.extract_json_from_string(solution)
                parsed_solutions.append(parsed_solution)

            # è®¡ç®— IoU
            for pred_dict, gt_dict in zip(parsed_solutions, solutions):
                pred_pick_bbox = torch.tensor(pred_dict["pick"]["bbox_2d"], dtype=torch.float32).unsqueeze(0)
                gt_pick_bbox = torch.tensor(gt_dict["pick"]["bbox_2d"], dtype=torch.float32).unsqueeze(0)
                pred_place_bbox = torch.tensor(pred_dict["place"]["bbox_2d"], dtype=torch.float32).unsqueeze(0)
                gt_place_bbox = torch.tensor(gt_dict["place"]["bbox_2d"], dtype=torch.float32).unsqueeze(0)

                pick_iou = box_iou(pred_pick_bbox, gt_pick_bbox).item()
                place_iou = box_iou(pred_place_bbox, gt_place_bbox).item()

                iou_scores.append({"pick_iou": pick_iou, "place_iou": place_iou})

            # è®¡ç®—åŠ¨ä½œè·ç¦»
            actions = np.array(actions)  # è½¬æ¢ä¸º numpy æ•°ç»„
            num_pots = np.prod(actions.shape)  # B*len*dim
            action_distance = TrainerUtils.euclidean_distance(normalized_actions, actions)
            average_action_distance = action_distance / num_pots
            action_distances.append(average_action_distance)

        # æ±‡æ€»ç»“æœ
        avg_action_distance = np.mean(action_distances)
        return {
            "iou_scores": iou_scores,
            "average_action_distance": avg_action_distance
        }

    @staticmethod
    def extract_json_from_string(input_string): # TODO è¿™ä¸ªæ–¹æ³•è§£è€¦æ€§ä¸å¤Ÿå¥½
        """
        ä»å­—ç¬¦ä¸²ä¸­æå–æœ‰æ•ˆçš„ JSON éƒ¨åˆ†å¹¶è½¬æ¢ä¸ºå­—å…¸ã€‚
        
        Args:
            input_string (str): åŒ…å«å¤šä½™å­—ç¬¦çš„å­—ç¬¦ä¸²ã€‚
        
        Returns:
            dict: æå–å¹¶è§£æåçš„å­—å…¸ã€‚
        """
        json_match = re.search(r"{.*}", input_string, re.DOTALL)
        if json_match:
            json_str = json_match.group(0)
            try:
                return json.loads(json_str)
            except json.JSONDecodeError as e:
                print(f"JSON è§£ç å¤±è´¥: {e}")
                return None
        else:
            print("æœªæ‰¾åˆ°æœ‰æ•ˆçš„ JSON éƒ¨åˆ†")
            return None
import os

def is_main_process(): # TODO è¦å˜æˆä¸€ä¸ªä¿®é¥°å‡½æ•°ï¼Œ ä½†æ˜¯æ˜¯å¦å¯ä»¥åƒ if ä½ è¦ä¿®é¥°ï¼Ÿ å°±æ˜¯ä¿®é¥°æ¯ä¸ªé€»è¾‘ï¼Ÿ
    rank = int(os.environ.get("RANK", 0))  # å¦‚æœæœªè®¾ç½® RANKï¼Œåˆ™é»˜è®¤ä¸º 0
    return rank == 0